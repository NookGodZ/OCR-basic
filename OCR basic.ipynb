{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955e9ff0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#OCR สมองควาย OCR ง่ายๆ \n",
    "import pytesseract as tess\n",
    "from PIL import Image\n",
    "\n",
    "tess.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "#location file picture \n",
    "name_pic = Image.open('OCR-Test2.jpg')\n",
    "\n",
    "#เปลี่ยนเป็นแสกน ภาษาไทย ได้แบบ tess.image_to_string(image, lang = 'thai')\n",
    "#เปลี่ยนเป็นแสกน อังฤษ+ภาษาไทย ได้แบบ tess.image_to_string(image, lang = 'tha+eng')\n",
    "\n",
    "text =   tess.image_to_string(name_pic,lang = 'tha+eng')\n",
    "\n",
    "print(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dc0707ff",
   "metadata": {},
   "source": [
    "OCR Bill Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95e56429",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pytesseract as tess\n",
    "import argparse\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6a51c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image=cv2.imread('bill3.png',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4d7fe3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ying thai kitchen\n",
      "2220 queen anne ave n\n",
      "seattle wa 98109\n",
      "« (206) 285-8424 fax. (206) 285-8427\n",
      "‘uw .yingthaikitchen.com\n",
      "welcome to ying thai kitchen restaurant.\n",
      "\n",
      "order#:17 table 2\n",
      "date: 7/4/2013 7:28 pm\n",
      "\n",
      "server: jack (1.4)\n",
      "44 ginger lover $9.50\n",
      "[pork] [24#]\n",
      "\n",
      "brown rice $2.00\n",
      "total 2 iten(s) $11.50\n",
      "sales tax $1.09\n",
      "grand total $12.59\n",
      "tip guide\n",
      "\n",
      "tek=$1.89, 18%=$2.27, 20%=82.52\n",
      "thank you very much,\n",
      "cone back again\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tess.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "text=(tess.image_to_string(image)).lower()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56ebe1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/4/2013\n"
     ]
    }
   ],
   "source": [
    "\n",
    "match=re.findall(r'\\d+[/.-]\\d+[/.-]\\d+', text)\n",
    "\n",
    "st=\" \"\n",
    "st=st.join(match)\n",
    "print(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fd3d086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt',quiet=True)\n",
    "nltk.download('wordnet',quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aff5578c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ying thai kitchen'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets try to extract title\n",
    "sent_tokens=nltk.sent_tokenize(text)\n",
    "#print(sent_tokens)\n",
    "sent_tokens[0].splitlines()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64219570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.59\n"
     ]
    }
   ],
   "source": [
    "#lets find the price of the category.\n",
    "price=re.findall(r'[\\$\\£\\€](\\d+(?:\\.\\d{1,2})?)',text)\n",
    "price = list(map(float,price)) \n",
    "print(max(price))\n",
    "x=max(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ea763b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ying', 'thai', 'kitchen', '2220', 'queen', 'anne', 'ave', 'n', 'seattle', 'wa', '98109', '«', '(', '206', ')', '285-8424', 'fax', '.', '(', '206', ')', '285-8427', '‘', 'uw', '.yingthaikitchen.com', 'welcome', 'to', 'ying', 'thai', 'kitchen', 'restaurant', '.', 'order', '#', ':17', 'table', '2', 'date', ':', '7/4/2013', '7:28', 'pm', 'server', ':', 'jack', '(', '1.4', ')', '44', 'ginger', 'lover', '$', '9.50', '[', 'pork', ']', '[', '24', '#', ']', 'brown', 'rice', '$', '2.00', 'total', '2', 'iten', '(', 's', ')', '$', '11.50', 'sales', 'tax', '$', '1.09', 'grand', 'total', '$', '12.59', 'tip', 'guide', 'tek=', '$', '1.89', ',', '18', '%', '=', '$', '2.27', ',', '20', '%', '=82.52', 'thank', 'you', 'very', 'much', ',', 'cone', 'back', 'again']\n"
     ]
    }
   ],
   "source": [
    "#till here we have extracted date,title and amount.\n",
    "#now its time to categorise bill whether it is shopping or grocery like wise\n",
    "#so i will first tokenise the text and search for key words\n",
    "print(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b3a18f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ying', 'thai', 'kitchen', '2220', 'queen', 'anne', 'ave', 'n', 'seattle', 'wa', '98109', '206', '285', '8424', 'fax', '206', '285', '8427', 'uw', 'yingthaikitchen', 'com', 'welcome', 'to', 'ying', 'thai', 'kitchen', 'restaurant', 'order', '17', 'table', '2', 'date', '7', '4', '2013', '7', '28', 'pm', 'server', 'jack', '1', '4', '44', 'ginger', 'lover', '9', '50', 'pork', '24', 'brown', 'rice', '2', '00', 'total', '2', 'iten', 's', '11', '50', 'sales', 'tax', '1', '09', 'grand', 'total', '12', '59', 'tip', 'guide', 'tek', '1', '89', '18', '2', '27', '20', '82', '52', 'thank', 'you', 'very', 'much', 'cone', 'back', 'again']\n"
     ]
    }
   ],
   "source": [
    "#we will remove punctuation\n",
    "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "new_words = tokenizer.tokenize(text)\n",
    "print(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd875d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\NookGodZ\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stop_words = set(nltk.corpus.stopwords.words('english')) \n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8da9538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are stop words like a ,an,the etc which are not required\n",
    "#so we need to filter them\n",
    "stop_words = set(nltk.corpus.stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8fad13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ying', 'thai', 'kitchen', '2220', 'queen', 'anne', 'ave', 'n', 'seattle', 'wa', '98109', '206', '285', '8424', 'fax', '206', '285', '8427', 'uw', 'yingthaikitchen', 'com', 'welcome', 'ying', 'thai', 'kitchen', 'restaurant', 'order', '17', 'table', '2', 'date', '7', '4', '2013', '7', '28', 'pm', 'server', 'jack', '1', '4', '44', 'ginger', 'lover', '9', '50', 'pork', '24', 'brown', 'rice', '2', '00', 'total', '2', 'iten', '11', '50', 'sales', 'tax', '1', '09', 'grand', 'total', '12', '59', 'tip', 'guide', 'tek', '1', '89', '18', '2', '27', '20', '82', '52', 'thank', 'much', 'cone', 'back']\n"
     ]
    }
   ],
   "source": [
    "#there is the filetred list\n",
    "filtered_list=[w for w in new_words if w not in stop_words ]\n",
    "print(filtered_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04a4f1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#entertainment\n",
    "entertainment = [] \n",
    "for syn in wordnet.synsets(\"entertainment\"): \n",
    "    for l in syn.lemmas(): \n",
    "        entertainment.append(l.name()) \n",
    "        \n",
    "l=['happy','restaurant','food','kitchen','hotel','room','park','movie','cinema','popcorn','combo meal']\n",
    "entertainment=entertainment+l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5227310b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#home utility\n",
    "home_utility=[] \n",
    "for syn in wordnet.synsets(\"home\"): \n",
    "    for l in syn.lemmas(): \n",
    "         home_utility.append(l.name()) \n",
    "l2=['internet','telephone','elecricity','meter','wifi','broadband','consumer','reading','gas','water','postpaid','prepaid']\n",
    "home_utility+=l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70f4449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grocery\n",
    " \n",
    "grocery=[] \n",
    "for syn in wordnet.synsets(\"grocery\"): \n",
    "    for l in syn.lemmas(): \n",
    "         grocery.append(l.name())\n",
    "l3=['bigbasket','milk','atta','sugar','suflower','oil','bread','vegetabe','fruit','salt','paneer']\n",
    "grocery+=l3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79414b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#investment\n",
    "investment=[] \n",
    "for syn in wordnet.synsets(\"investment\"): \n",
    "    for l in syn.lemmas(): \n",
    "         investment.append(l.name()) \n",
    "l1=['endowment','grant','loan','applicant','income','expenditure','profit','interest','expense','finance','property','money','fixed','deposit','kissan','vikas']\n",
    "investment=investment+l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c220c267",
   "metadata": {},
   "outputs": [],
   "source": [
    "#travel and transportation\n",
    "transport=[]\n",
    "for syn in wordnet.synsets(\"car\"): \n",
    "    for l in syn.lemmas(): \n",
    "         transport.append(l.name()) \n",
    "l4=['cab','ola','uber','autorickshaw','railway','air','emirates','aerofloat','taxi','booking','road','highway']\n",
    "transport+=l4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c405947",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shopping\n",
    "shopping=[]\n",
    "for syn in wordnet.synsets(\"dress\"): \n",
    "    for l in syn.lemmas(): \n",
    "         shopping.append(l.name()) \n",
    "l4=['iphone','laptop','saree','max','pantaloons','westside','vedic','makeup','lipstick','cosmetics','mac','facewash','heels','crocs','footwear','purse']\n",
    "shopping+=l4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee60f8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we will check that the bill belongs to which category\n",
    "#we will make that category true.\n",
    "for word in filtered_list:\n",
    "    if word in entertainment:\n",
    "        e=True\n",
    "        break\n",
    "    elif word in investment:\n",
    "        inv=True\n",
    "        break\n",
    "    elif word in grocery:\n",
    "        g=True\n",
    "        break\n",
    "    elif word in shopping:\n",
    "        s=True\n",
    "        break\n",
    "    elif word in transport:\n",
    "        t=True\n",
    "        break\n",
    "    elif word in home_utility:\n",
    "        h=True\n",
    "        break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ddb9d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"with open('entertainment1.csv', 'a', newline='') as csvfile:\\n    spamwriter = csv.writer(csvfile, delimiter=',',quoting=csv.QUOTE_MINIMAL)\\n    spamwriter.writerow(['date','organisation','amount'])\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is how i created all the csv files.\n",
    "'''with open('entertainment1.csv', 'a', newline='') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',',quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writerow(['date','organisation','amount'])'''\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24d18154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entertainment category\n"
     ]
    }
   ],
   "source": [
    "#question 2\n",
    "#this code the category in which the bill belongs to\n",
    "#if e is true then entertainment categrory and we will ,ake filename as entertainment.csv using\n",
    "#formatting\n",
    "if(e):\n",
    "    print(\"entertainment category\")\n",
    "    filename='{}.csv'.format('entertainment')\n",
    "    #df=pd.read_csv('entertainment.csv')\n",
    "elif(inv):\n",
    "    print(\"investment category\")\n",
    "    filename='{}.csv'.format('investment')\n",
    "    #df=pd.read_csv('investment.csv')\n",
    "elif(s):\n",
    "    print(\"shopping category\")\n",
    "    filename='{}.csv'.format('shopping')\n",
    "    #df=pd.read_csv('shopping.csv')\n",
    "elif(g):\n",
    "    print(\"grocery category\")\n",
    "    filename='{}.csv'.format('grocery')\n",
    "    #df=pd.read_csv('grocery.csv')\n",
    "elif(t):\n",
    "    print(\"transport category\")\n",
    "    filename='{}.csv'.format('transport')\n",
    "    #df=pd.read_csv('transport.csv')\n",
    "elif(h):\n",
    "    print(\"home utility category\")\n",
    "    filename='{}.csv'.format('home')\n",
    "    #df=pd.read_csv('home.csv')\n",
    "else:\n",
    "    print(\"others\")\n",
    "    filename='{}.csv'.format('others')\n",
    "    #df=pd.read_csv('others.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "98cd5d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the contents in thier respective csv file\n",
    "row_contents = ['st','head','x']\n",
    "\n",
    "from csv import writer\n",
    " \n",
    "def append_list_as_row(file, list_of_elem):\n",
    "   \n",
    "    with open(file, 'a+', newline='') as write_obj:\n",
    "       \n",
    "        csv_writer = writer(write_obj)\n",
    "        \n",
    "        csv_writer.writerow(list_of_elem)\n",
    "append_list_as_row(filename, row_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d3c82d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'investment.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13120/3956892309.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#after this make sure you save it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mentertainment\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'entertainment.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0minvestment\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'investment.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mshopping\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'shopping.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mgrocery\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'grocery.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'investment.csv'"
     ]
    }
   ],
   "source": [
    "#after this make sure you save it\n",
    "entertainment=pd.read_csv('entertainment.csv')\n",
    "investment=pd.read_csv('investment.csv')\n",
    "shopping=pd.read_csv('shopping.csv')\n",
    "grocery=pd.read_csv('grocery.csv')\n",
    "transport=pd.read_csv('transport.csv')\n",
    "other=pd.read_csv('others.csv')\n",
    "home=pd.read_csv('home.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5ed077",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
